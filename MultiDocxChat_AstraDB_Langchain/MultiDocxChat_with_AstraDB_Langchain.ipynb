{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.5/300.5 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m444.0/444.0 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
      "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.5/310.5 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.3/172.3 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.6/167.6 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.8/207.8 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m483.4/483.4 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "# 1. Core LangChain + integrations\n",
    "!pip install -U langchain langchain-huggingface -q\n",
    "!pip install langchain_community langchain_google_genai langchain-astradb -q\n",
    "\n",
    "# 2. Document loaders (pptx, pdf, text, unstructured)\n",
    "!pip install python-pptx pypdf unstructured -q\n",
    "\n",
    "# 3. Clean up old Hugging Face libs (remove conflicts)\n",
    "!pip uninstall -y sentence-transformers transformers -q\n",
    "\n",
    "# 4. Reinstall modern Hugging Face + Torch stack\n",
    "!pip install -U torch transformers sentence-transformers -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import userdata\n",
    "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
    "ASTRADB_TOKEN = userdata.get('ASTRADB_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86f86413cd1b43b4ab785c36b0c075d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a02b46ad6ef439f820c88a2879b8d42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "801a31286b584c2589e579a46a3935c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2482d09b4ef4e31b49d992fe84385e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4141e4c9e6164917a12eb0d8a540aa53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2b9590a06fc459ba10527ec758e5c31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26af1dba57aa46bd8e2b1915557a4b46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae0b1ac3d8e34ae69e85ed4119fc2d0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6bbb7d77a3d48efb82ea2de432eeba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99f6d5845de944d699e72fd3627e81ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f62753433c649edbf07c31f3d3302a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# Best quality HuggingFace embedding model\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-mpnet-base-v2\",\n",
    "    model_kwargs={\"device\": \"cpu\"}  # or \"cuda\" if GPU is available\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['movies_top_ten.txt', 'aaa_games_info.pdf', 'Generative_AI_Roadmap.pptx']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_dir=\"/content/\"\n",
    "docs_folder_path = f'{root_dir}/docs/'\n",
    "os.listdir(docs_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3 chunks from docs/\n",
      "page_content='Text: Top 10 IMDb Movies\n",
      "\n",
      "1. The Shawshank Redemption (1994)\n",
      "Directed by Frank Darabont. Starring Tim Robbins and Morgan Freeman.\n",
      "A powerful story of hope and friendship inside Shawshank prison. Andy Dufresne, sentenced for a crime he didn’t commit, builds a legacy of resilience and justice.\n",
      "\n",
      "2. The Godfather (1972)\n",
      "Directed by Francis Ford Coppola. Starring Marlon Brando and Al Pacino.\n",
      "An epic saga of the Corleone mafia family, exploring power, loyalty, and betrayal in organized crime.\n",
      "\n",
      "3. The Dark Knight (2008)\n",
      "Directed by Christopher Nolan. Starring Christian Bale and Heath Ledger.\n",
      "A gritty superhero masterpiece where Batman faces his deadliest rival, the Joker, in a moral battle for Gotham City.\n",
      "\n",
      "4. The Godfather Part II (1974)\n",
      "Directed by Francis Ford Coppola. Starring Al Pacino and Robert De Niro.\n",
      "A dual narrative showing the rise of young Vito Corleone and Michael Corleone’s consolidation of power.\n",
      "\n",
      "5. 12 Angry Men (1957)\n",
      "Directed by Sidney Lumet. Starring Henry Fonda and Lee J. Cobb.\n",
      "A courtroom drama where 12 jurors debate the fate of a young man accused of murder. A study of justice and prejudice.\n",
      "\n",
      "6. Schindler’s List (1993)\n",
      "Directed by Steven Spielberg. Starring Liam Neeson, Ben Kingsley, and Ralph Fiennes.\n",
      "The true story of Oskar Schindler, a German industrialist who saved over 1,000 Jews during the Holocaust.\n",
      "\n",
      "7. The Lord of the Rings: The Return of the King (2003)\n",
      "Directed by Peter Jackson. Starring Elijah Wood, Viggo Mortensen, and Ian McKellen.\n",
      "The final installment of the epic fantasy trilogy, where Frodo and Sam reach Mount Doom to destroy the One Ring.\n",
      "\n",
      "8. Pulp Fiction (1994)\n",
      "Directed by Quentin Tarantino. Starring John Travolta, Samuel L. Jackson, and Uma Thurman.\n",
      "An interwoven story of crime and redemption in Los Angeles, famous for its nonlinear narrative and sharp dialogue.\n",
      "\n",
      "9. The Good, the Bad and the Ugly (1966)\n",
      "Directed by Sergio Leone. Starring Clint Eastwood, Eli Wallach, and Lee Van Cleef.\n",
      "A spaghetti western classic about three gunslingers competing to find buried Confederate gold.\n",
      "\n",
      "10. The Lord of the Rings: The Fellowship of the Ring (2001)\n",
      "Directed by Peter Jackson. Starring Elijah Wood, Ian McKellen, and Orlando Bloom.\n",
      "The first film in the trilogy, introducing the Fellowship’s journey to destroy the One Ring.' metadata={'source': '/content//docs/movies_top_ten.txt'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import (\n",
    "    PyPDFLoader,\n",
    "    TextLoader,\n",
    "    UnstructuredPowerPointLoader\n",
    ")\n",
    "import os\n",
    "\n",
    "docs_path = docs_folder_path\n",
    "documents = []\n",
    "\n",
    "for file in os.listdir(docs_path):\n",
    "    file_path = os.path.join(docs_path, file)\n",
    "\n",
    "    if file.endswith(\".pdf\"):\n",
    "        loader = PyPDFLoader(file_path)\n",
    "    elif file.endswith(\".txt\"):\n",
    "        loader = TextLoader(file_path, encoding=\"utf-8\")\n",
    "    elif file.endswith(\".pptx\"):\n",
    "        loader = UnstructuredPowerPointLoader(file_path)\n",
    "    else:\n",
    "        continue  # skip unsupported files\n",
    "\n",
    "    documents.extend(loader.load())\n",
    "\n",
    "print(f\"Loaded {len(documents)} chunks from docs/\")\n",
    "print(documents[0])  # preview first chunk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 2: Using Unstructured Loader (UnstructuredFileLoader)\n",
    "\n",
    "👉 Handles multiple formats automatically (PDF, TXT, PPTX, DOCX, HTML, etc.) with OCR + layout parsing.\n",
    "⚠️ Requires Python ≤ 3.11 (not yet Py3.12-ready).\n",
    "\n",
    "```\n",
    "from langchain_community.document_loaders import UnstructuredFileLoader\n",
    "import os\n",
    "\n",
    "docs_path = \"docs/\"\n",
    "documents = []\n",
    "\n",
    "for file in os.listdir(docs_path):\n",
    "    file_path = os.path.join(docs_path, file)\n",
    "    \n",
    "    if file.lower().endswith((\".pdf\", \".txt\", \".pptx\")):\n",
    "        loader = UnstructuredFileLoader(file_path, mode=\"elements\")  # \"elements\" = structured chunks\n",
    "        documents.extend(loader.load())\n",
    "\n",
    "print(f\"Loaded {len(documents)} structured chunks from docs/\")\n",
    "print(documents[0])  # preview first structured chunk\n",
    "```\n",
    "Pros: Auto-handles multiple formats, OCR support, keeps structure.\n",
    "\n",
    "Cons: Heavy dependencies (onnxruntime, tesseract, etc.), not stable in Python 3.12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After splitting: 16 chunks\n",
      "page_content='Text: Top 10 IMDb Movies\n",
      "\n",
      "1. The Shawshank Redemption (1994)\n",
      "Directed by Frank Darabont. Starring Tim Robbins and Morgan Freeman.\n",
      "A powerful story of hope and friendship inside Shawshank prison. Andy Dufresne, sentenced for a crime he didn’t commit, builds a legacy of resilience and justice.\n",
      "\n",
      "2. The Godfather (1972)\n",
      "Directed by Francis Ford Coppola. Starring Marlon Brando and Al Pacino.\n",
      "An epic saga of the Corleone mafia family, exploring power, loyalty, and betrayal in organized crime.\n",
      "\n",
      "3. The Dark Knight (2008)\n",
      "Directed by Christopher Nolan. Starring Christian Bale and Heath Ledger.\n",
      "A gritty superhero masterpiece where Batman faces his deadliest rival, the Joker, in a moral battle for Gotham City.\n",
      "\n",
      "4. The Godfather Part II (1974)\n",
      "Directed by Francis Ford Coppola. Starring Al Pacino and Robert De Niro.\n",
      "A dual narrative showing the rise of young Vito Corleone and Michael Corleone’s consolidation of power.' metadata={'source': '/content//docs/movies_top_ten.txt'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Create a text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,   # max characters per chunk\n",
    "    chunk_overlap=200, # overlap between chunks to preserve context\n",
    "    length_function=len,\n",
    ")\n",
    "\n",
    "# Apply to all docs\n",
    "split_documents = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"After splitting: {len(split_documents)} chunks\")\n",
    "print(split_documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_astradb import AstraDBVectorStore\n",
    "ASTRADB_ENDPOINT = \"https://d8b9caac-52cc-49fc-b343-8c5c0ce2c937-us-east-2.apps.astra.datastax.com\"\n",
    "# ASTRADB_TOKEN\n",
    "ASTRA_DB_KEYSPACE = \"default_keyspace\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vstore = AstraDBVectorStore(\n",
    "    embedding=embeddings,\n",
    "    collection_name=\"multidocs_astra_langchain_collection\",\n",
    "    api_endpoint=ASTRADB_ENDPOINT,\n",
    "    token=ASTRADB_TOKEN,\n",
    "    namespace=ASTRA_DB_KEYSPACE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['f5c239fc8b1f49e6988a5a706fb70d5b',\n",
       " '9d1e4af323354cf180970e0b25099808',\n",
       " '880bc461d8d24192aa6361fff6dbdcfe',\n",
       " '67043300d2d34967bcd91cd738f81534',\n",
       " '44524dcf245448f6b6934b39cafdd5fb',\n",
       " 'bd4734f1e2ad4ee7823f7f1f1422aaa9',\n",
       " '4474d879c9974045b51a96f9e8953034',\n",
       " 'eb3fe3926f174770a680692d2ddfff54',\n",
       " 'f2172b811a164884ac7f1622862812cf',\n",
       " '46d4e75344684e27b050b6121ad6a223',\n",
       " 'bee45ce46560435ba2ef75ccdc45a7df',\n",
       " 'ce52ad8e4ddd4aaea5300aa997b518b1',\n",
       " 'bb66075a28fa44a2beabd4613e79d643',\n",
       " 'd819fc3e85ab4eb7a3e17785d9d64e48',\n",
       " '01d5964442f94973a50183c3b3d89e2d',\n",
       " '5bcf29fcbe12417192e1b3fcab712637']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vstore.add_documents(split_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vstore.as_retriever(\n",
    "    search_type=\"similarity\",  # or \"mmr\" for diversity\n",
    "    search_kwargs={\"k\": 3}     # top 3 most relevant chunks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 retrieved chunks:\n",
      "\n",
      "--- Chunk 1 ---\n",
      "AAA Games Information\n",
      "1. Cyberpunk 2077 - Company: CD Projekt Red - Release Year: 2020 - Sales: Over 25 million copies\n",
      "sold by 2023 - Revenue: Estimated over $750 million from initial release and expansions - Notes:\n",
      "Despite a troubled launch with bugs, post-launch patches and the \"Phantom Liberty\" e ...\n",
      "\n",
      "--- Chunk 2 ---\n",
      "Math and statistics are fundamental for data science and AI as they draw meaningful insights from complex datasets.\n",
      "\n",
      "\n",
      "\n",
      "Topics to Learn in Statistics\n",
      "\n",
      "Descriptive statistics\n",
      "\n",
      "Inferential statistics\n",
      "\n",
      "Basic plot in statistics\n",
      "\n",
      "Measure of central tendency\n",
      "\n",
      "Types of distributions\n",
      "\n",
      "Central limit theorem\n",
      "\n",
      " ...\n",
      "\n",
      "--- Chunk 3 ---\n",
      "Generative AI\n",
      "\n",
      "Roadmap 2024\n",
      "\n",
      "\n",
      "\n",
      "From Basics to Advanced\n",
      "\n",
      "Here's a step-by-step guide designed for absolute beginners looking to acquire skills in Generative AI. \n",
      "\n",
      "Different Positions or Different Levels:  \n",
      "\n",
      "Developer Level 1 or Beginner Level \n",
      "\n",
      "Developer Level 2 or Senior Level\n",
      "\n",
      " Researcher Leve\n",
      "\n",
      "\n",
      "\n",
      " ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What is discussed in the PDF about Cyberpunk 2077 sales?\"\n",
    "\n",
    "# Convert query into an embedding\n",
    "query_embedding = embeddings.embed_query(query)\n",
    "\n",
    "# Perform similarity search directly on AstraDB\n",
    "results = vstore.similarity_search(query, k=3)\n",
    "\n",
    "print(f\"Top {len(results)} retrieved chunks:\\n\")\n",
    "for i, doc in enumerate(results, 1):\n",
    "    print(f\"--- Chunk {i} ---\")\n",
    "    print(doc.page_content[:300], \"...\\n\")  # preview text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are a helpful assistant.\n",
    "Use the following context to answer the question:\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model = \"gemini-2.5-flash-lite\", api_key = GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke(\"can you tell me the roadmap of generative ai?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: The roadmap for Generative AI, as outlined in the document, is a step-by-step guide for beginners to acquire skills. It's broken down into several sections:\n",
      "\n",
      "*   **Prerequisite:** This section likely covers foundational knowledge needed before diving into Generative AI.\n",
      "*   **Fundamentals:** This section will cover the basic concepts of Generative AI.\n",
      "*   **Core Generative Models:** This section delves into the main types of generative models, including:\n",
      "    *   **Generative Image Models:** Such as GANs (Generative Adversarial Networks), Variational Autoencoders (VAEs), and Diffusion Models (like Stable Diffusion).\n",
      "    *   **Generative Language Models (LLMs):** Which are focused on natural language processing. Milestone LLM models mentioned include BERT, GPT, XLM, T5, Megatron, and M2M-100. Specific OpenAI LLM models highlighted are GPT-4, GPT-4 Turbo, GPT-3.5, and DALL·E.\n",
      "*   **Developing Applications Powered by LLMs:** This section focuses on building applications that utilize Large Language Models.\n",
      "*   **Projects and Practical Experience:** This is crucial for hands-on learning and applying the acquired knowledge.\n",
      "*   **Miscellaneous Topics:** This section likely covers other relevant areas not fitting into the main categories.\n",
      "*   **Advice for Productive Learning:** This includes tips like defining goals, consistent learning, implementing knowledge, experimenting, and seeking feedback.\n",
      "*   **FAQs:** This section addresses common questions, such as whether a background in machine learning or deep learning is required (a basic understanding is beneficial, and introductory courses can help).\n",
      "\n",
      "The document also mentions that Generative AI is a very huge topic and can generate various types of data, including images, text, audio, and videos. For training these models, high-performance GPUs are recommended, and various cloud platforms and services like GCP, AWS, Azure, PaperSpace, Google Colab, and Kaggle instances are suggested. Continuous learning by keeping up with news, trends, research papers, and the community is also emphasized.\n"
     ]
    }
   ],
   "source": [
    "print(\"Answer:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
